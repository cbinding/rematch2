{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find compound terms where the last word doesn't exist in the vocabulary\n",
    "import json\n",
    "import re\n",
    "\n",
    "# read json file to list [ {id, term}, {id, term}, ... ]\n",
    "def read_data(file_name: str=\"\") -> list:\n",
    "    data = []\n",
    "    with open(file_name, mode=\"r\", encoding=\"utf-8\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "    return list(map(lambda item: {\"id\": item.get(\"id\", \"\"), \"term\": item.get(\"pattern\", \"\")}, data))\n",
    "\n",
    "\n",
    "def term_exists(term: str=\"\", data: list=[]) -> bool:\n",
    "    terms = list(map(lambda item: item.get(\"term\", \"\").strip().lower(), data))\n",
    "    clean = term.strip().lower()\n",
    "    return any(t ==  clean for t in terms)\n",
    "\n",
    "\n",
    "def is_compound(term: str=\"\") -> bool: return len(term.split()) > 1\n",
    "\n",
    "\n",
    "def get_last_word(term: str=\"\") -> str: return term.split()[-1]\n",
    "\n",
    "\n",
    "def clean_term(term: str=\"\") -> str:\n",
    "    cleaned = term.strip() # strip leading and training spaces  \n",
    "    cleaned = re.sub(r\"\\s*\\<[^\\>]+\\>\", \"\", cleaned) # remove angle bracket qualifiers\n",
    "    cleaned = re.sub(r\"\\s*\\([^\\)]+\\)\", \"\", cleaned) # remove round bracket qualifiers\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def get_compound_terms_1():\n",
    "    INPUT_FILE = \"./rematch2/vocabularies/patterns_en_FISH_ARCHOBJECTS_20210921.json\"\n",
    "    OUTPUT_FILE = \"./data/tmp/compound-terms-final-word-not-in-objects-thesaurus.txt\"\n",
    "    with open(OUTPUT_FILE, 'w') as output:\n",
    "        data = read_data(INPUT_FILE)\n",
    "        for item in data:\n",
    "            uri = item.get(\"id\", \"\")\n",
    "            term = item.get(\"term\", \"\")\n",
    "            clean = clean_term(term)\n",
    "            last = get_last_word(clean)    \n",
    "            if is_compound(clean) and not term_exists(last, data):\n",
    "                output.write(f\"{uri}\\t\\\"{term}\\\"\\t\\\"{last}\\\"\\n\")\n",
    "\n",
    "\n",
    "def get_compound_terms_2():\n",
    "    INPUT_FILE = \"./rematch2/vocabularies/patterns_en_FISH_MONUMENT_TYPES_20210921.json\"\n",
    "    OUTPUT_FILE = \"./data/tmp/compound-terms-final-word-not-in-monuments-thesaurus.txt\"\n",
    "    with open(OUTPUT_FILE, 'w') as output:\n",
    "        data = read_data(INPUT_FILE)\n",
    "        for item in data:\n",
    "            uri = item.get(\"id\", \"\")\n",
    "            term = item.get(\"term\", \"\")\n",
    "            clean = clean_term(term)\n",
    "            last = get_last_word(clean)    \n",
    "            if is_compound(clean) and not term_exists(last, data):\n",
    "                output.write(f\"{uri}\\t\\\"{term}\\\"\\t\\\"{last}\\\"\\n\")\n",
    "\n",
    "\n",
    "def get_compound_terms_3():\n",
    "    INPUT_FILE = \"./rematch2/vocabularies/patterns_en_FISH_ARCHOBJECTS_20210921.json\"\n",
    "    OUTPUT_FILE = \"./data/tmp/compound-terms-in-objects-thesaurus-with-bracketed-suffix.txt\"\n",
    "    with open(OUTPUT_FILE, 'w') as output:\n",
    "        data = read_data(INPUT_FILE)\n",
    "        for item in data:\n",
    "            uri = item.get(\"id\", \"\")\n",
    "            term = item.get(\"term\", \"\")\n",
    "            m = re.search(r\"\\s*\\<[^\\>]+\\>\", term)\n",
    "            if m: output.write(f\"{uri}\\t\\\"{term}\\\"\\n\")\n",
    "            m = re.search(r\"\\s*\\([^\\>]+\\)\", term)\n",
    "            if m: output.write(f\"{uri}\\t\\\"{term}\\\"\\n\")\n",
    "\n",
    "\n",
    "def get_compound_terms_4():\n",
    "    INPUT_FILE = \"./rematch2/vocabularies/patterns_en_FISH_MONUMENT_TYPES_20210921.json\"\n",
    "    OUTPUT_FILE = \"./data/tmp/compound-terms-in-monuments-thesaurus-with-bracketed-suffix.txt\"\n",
    "    with open(OUTPUT_FILE, 'w') as output:\n",
    "        data = read_data(INPUT_FILE)\n",
    "        for item in data:\n",
    "            uri = item.get(\"id\", \"\")\n",
    "            term = item.get(\"term\", \"\")\n",
    "            m = re.search(r\"\\s*\\<[^\\>]+\\>\", term)\n",
    "            if m: output.write(f\"{uri}\\t\\\"{term}\\\"\\n\")\n",
    "            m = re.search(r\"\\s*\\([^\\>]+\\)\", term)\n",
    "            if m: output.write(f\"{uri}\\t\\\"{term}\\\"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_compound_terms_1()\n",
    "    get_compound_terms_2()\n",
    "    get_compound_terms_3()\n",
    "    get_compound_terms_4()\n",
    "       \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

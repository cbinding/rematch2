{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process OASIS records\n",
    "Vocabulary-based Named Entity Recognition (NER) applied to a set of XML OASIS abstracts obtained from ADS. Detecting temporal phrases and object/monument types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (24.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spacy in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipywidgets) (8.24.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: decorator in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "# suppress user warnings during execution\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "# load required dependencies\n",
    "%pip install --upgrade pip\n",
    "%pip install spacy\n",
    "%pip install ipywidgets\n",
    "%sx python -m spacy download en_core_web_sm\n",
    "\n",
    "#from IPython.display import display, HTML\n",
    "from slugify import slugify # for valid filenames from identifiers\n",
    "import spacy # for NER processing\n",
    "from spacy.tokens import Doc # for NER results\n",
    "from lxml import etree as ET # for parsing input records from XML file\n",
    "from datetime import datetime as DT # for timestamps\n",
    "from html import escape # for writing escaped HTML\n",
    "\n",
    "from rematch2 import PeriodoRuler, VocabularyRuler, NegationRuler, DocSummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# write ISO timestamp in consistent format\n",
    "def timestamp():\n",
    "  return DT.now().strftime('%Y-%m-%dT%H:%M:%SZ')  \n",
    "\n",
    "# normalize string whitespace\n",
    "def normalize_whitespace(s: str = \"\") -> str: \n",
    "    return ' '.join(s.strip().split()) \n",
    "    \n",
    "# parse and extract a list of OASIS abstract records from source XML file \n",
    "# returns [{\"id\", \"text\"}, {\"id\", \"text\"}, ...] for subsequent processing\n",
    "def get_records_from_xml_file(file_path: str=\"\") -> list:\n",
    "    records = []\n",
    "    try:\n",
    "        # read XML file\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "    except:\n",
    "        print(f\"Could not read from {file_path}\")\n",
    "        return []\n",
    "\n",
    "    # find rows to be processed in the XML file\n",
    "    rows = tree.xpath(\"/table/rows/row\")\n",
    "\n",
    "    for row in rows:\n",
    "        # find abstract(s) in the current item\n",
    "        abstracts = row.xpath(\"value[@columnNumber='1']/text()\")\n",
    "       \n",
    "        # if multiple abstracts, get first one\n",
    "        if (len(abstracts) > 0):\n",
    "            abstract = abstracts[0]\n",
    "        else:\n",
    "            abstract = \"\"\n",
    "\n",
    "         # find identifier(s) in the current item\n",
    "        identifiers = row.xpath(\"value[@columnNumber='0']/text()\")\n",
    "\n",
    "        # if multiple identifiers, get first one (remove URL prefix if present)\n",
    "        if (len(identifiers) > 0):\n",
    "            identifier = identifiers[0]\n",
    "            identifier = identifier.replace(\n",
    "                \"https://archaeologydataservice.ac.uk/archsearch/record?titleId=\", \"\")\n",
    "        else:\n",
    "            identifier = \"\"\n",
    "\n",
    "        ## create new (cleaned) record and add it\n",
    "        record = {}\n",
    "        record[\"id\"] = identifier.strip()\n",
    "        record[\"text\"] = abstract.strip()\n",
    "        records.append(record)\n",
    "\n",
    "    # finally, return the extracted list\n",
    "    return records\n",
    "\n",
    "# write single results as a HTML file for presentation of output\n",
    "def write_html_file(file_name: str=\"\", doc: Doc = None, metadata: dict = {}):\n",
    "    summary = DocSummary(doc)\n",
    "    html = []\n",
    "\n",
    "    # write header tags\n",
    "    html.append(\"<!DOCTYPE html>\")\n",
    "    html.append(\"<html>\")\n",
    "        \n",
    "    # write CSS from file to style tag (so no file dependency)\n",
    "    html.append(\"<head>\")\n",
    "    with open('find_pairs.css', 'r', encoding='utf8') as css_file:\n",
    "        css_text = css_file.read()\n",
    "        html.append(f'<style>{css_text}</style>')    \n",
    "    \n",
    "    html.append(\"</head>\")\n",
    "    html.append(\"<body>\")\n",
    "\n",
    "    def metadata_value(key: str) -> str: return metadata.get(key.strip(), \"\").strip()\n",
    "\n",
    "    # write identifier as heading\n",
    "    html.append(\"<h3>\")\n",
    "    identifier = metadata_value(\"identifier\")   \n",
    "    if(identifier.startswith(\"http\")):\n",
    "        html.append(f\"<a target='_blank' rel='noopener noreferrer' href='{identifier}'>{escape(identifier)}</a>\")\n",
    "    else:\n",
    "        html.append(f\"{escape(identifier)}\")\n",
    "    html.append(\"</h3>\")\n",
    "\n",
    "    # write metadata   \n",
    "    html.append(\"<details>\")\n",
    "    html.append(f\"<summary>Metadata</summary>\")\n",
    "    html.append(\"<ul>\")\n",
    "    html.append(f\"<li><strong>identifier:</strong> {escape(metadata_value(\"identifier\"))}</li>\")\n",
    "    html.append(f\"<li><strong>title:</strong> {escape(metadata_value(\"title\"))}</li>\")\n",
    "    html.append(f\"<li><strong>description:</strong> {escape(metadata_value(\"description\"))}</li>\")\n",
    "    html.append(f\"<li><strong>creator:</strong> {escape(metadata_value(\"creator\"))}</li>\")\n",
    "    html.append(f\"<li><strong>created:</strong> {escape(metadata_value(\"timestamp\"))}</li>\")\n",
    "    html.append(f\"<li><strong>periodo authority ID:</strong> {escape(metadata_value(\"periodo_authority_id\"))}</li>\")\n",
    "\n",
    "    pipeline = metadata.get('ner_pipeline', [])\n",
    "    def listitem(value: str) -> str: return f\"<li>{escape(value)}</li>\"\n",
    "    pipelist = \"<ul>\" + \"\".join(list(map(listitem, pipeline))) + \"</ul>\"\n",
    "    html.append(f\"<li><strong>NER pipeline:</strong>{pipelist}</li>\")\n",
    "    html.append(\"</ul>\")\n",
    "    html.append(\"</details>\")    \n",
    "\n",
    "    # write displacy HTML rendering of doc text as paragraph with highlighted spans \n",
    "    html.append(\"<details open>\")\n",
    "    html.append(f\"<summary>Text ({len(summary.doctext('text'))} characters)</summary>\")\n",
    "    doctext = summary.doctext(format=\"html\")\n",
    "    html.append(f\"<p>{doctext}</p>\")\n",
    "    html.append(\"</details>\")\n",
    "\n",
    "    # write list of tokens\n",
    "    html.append(\"<details>\")\n",
    "    html.append(f\"<summary>Tokens ({len(summary.tokens('list'))})</summary>\")        \n",
    "    html.append(summary.tokens(\"htmll\"))\n",
    "    html.append(\"</details>\")\n",
    "\n",
    "    # write label counts\n",
    "    #html.append(\"<details>\")\n",
    "    #html.append(f\"<summary>Label Counts ({len(DocSummary(doc).labelcounts('list'))})</summary>\")\n",
    "    #html.append(DocSummary(doc).labelcounts(format=\"htmlt\"))\n",
    "    #html.append(\"</details>\")\n",
    "    \n",
    "    # write span counts\n",
    "    html.append(\"<details>\")\n",
    "    html.append(f\"<summary>Span Counts ({len(DocSummary(doc).spancounts('list'))})</summary>\")\n",
    "    html.append(DocSummary(doc).spancounts(format=\"htmlt\"))\n",
    "    html.append(\"</details>\")\n",
    "    \n",
    "    # get and write span pairs\n",
    "    html.append(\"<details>\")\n",
    "    html.append(f\"<summary>Span Pairs</summary>\")\n",
    "    pairs = summary.spanpairs(\n",
    "        format=\"htmlt\", \n",
    "        rel_ops=[ \"<\", \">\", \"<<\", \">>\", \".\", \";\" ], \n",
    "        left_labels=[\"PERIOD\", \"YEARSPAN\"], \n",
    "        right_labels=[\"OBJECT\", \"MONUMENT\"]\n",
    "        )\n",
    "    html.append(pairs)\n",
    "    html.append(\"</details>\")\n",
    "\n",
    "    html.append(\"<details>\")\n",
    "    html.append(f\"<summary>Negated Pairs</summary>\")\n",
    "    pairs = summary.spanpairs(\n",
    "        format=\"htmlt\", \n",
    "        rel_ops=[ \"<\", \">\", \"<<\", \">>\", \".\", \";\" ], \n",
    "        left_labels=[\"NEGATION\"], \n",
    "        right_labels=[\"YEARSPAN\", \"PERIOD\", \"OBJECT\", \"MONUMENT\"]\n",
    "        )\n",
    "    html.append(pairs)\n",
    "    html.append(\"</details>\")\n",
    "    # write footer tags\n",
    "    html.append(\"</body>\")\n",
    "    html.append(\"</html>\")\n",
    "        \n",
    "    # finally, write HTML as string to file\n",
    "    with open(file_name, \"w\") as html_file:\n",
    "        html_file.write(\"\".join(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing record 1 of 1692 [ID: cambridg1-30423]\n",
      "processing record 2 of 1692 [ID: universi1-91218]\n",
      "processing record 3 of 1692 [ID: preconst1-3588]\n",
      "processing record 4 of 1692 [ID: preconst1-3588]\n",
      "processing record 5 of 1692 [ID: cambridg3-76125]\n",
      "processing record 6 of 1692 [ID: preconst1-4915]\n",
      "processing record 7 of 1692 [ID: aocarcha1-129642]\n",
      "processing record 8 of 1692 [ID: thamesva1-93666]\n",
      "processing record 9 of 1692 [ID: fieldsec1-100417]\n",
      "processing record 10 of 1692 [ID: trentpea1-324597]\n",
      "processing record 11 of 1692 [ID: archaeol7-404823]\n",
      "processing record 12 of 1692 [ID: cotswold2-93883]\n",
      "processing record 13 of 1692 [ID: colchest3-92994]\n",
      "processing record 14 of 1692 [ID: tyneandw3-6189]\n",
      "processing record 15 of 1692 [ID: essexcou1-41978]\n",
      "processing record 16 of 1692 [ID: molas1-8593]\n",
      "processing record 17 of 1692 [ID: eastsuss3-7591]\n",
      "processing record 18 of 1692 [ID: archaeol6-186501]\n",
      "processing record 19 of 1692 [ID: surreyco1-105591]\n",
      "processing record 20 of 1692 [ID: archaeol7-27583]\n"
     ]
    }
   ],
   "source": [
    "periodo_authority_id = \"p0kh9ds\" # HE Periods list\n",
    "# use predefined spaCy pipeline (English)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable = ['ner'])\n",
    "# add rematch2 NER component(s) to the end of the pipeline\n",
    "nlp.add_pipe(\"yearspan_ruler\", last=True)    \n",
    "nlp.add_pipe(\"periodo_ruler\", last=True, config={\"periodo_authority_id\": periodo_authority_id}) \n",
    "nlp.add_pipe(\"fish_archobjects_ruler\", last=True)\n",
    "nlp.add_pipe(\"fish_monument_types_ruler\", last=True)  \n",
    "nlp.add_pipe(\"fish_supplementary_ruler\", last=True) \n",
    "nlp.add_pipe(\"negation_ruler\", last=True) \n",
    "\n",
    "input_records = get_records_from_xml_file(\"./data/input/oasis_descr_examples.xml\")\n",
    "record_count = len(input_records)\n",
    "\n",
    "metadata = {\n",
    "    \"title\": \"process_oasis_records results\",\n",
    "    \"description\": \"vocabulary-based NER annotation of archaeology abstracts\",\n",
    "    \"creator\": \"process_oasis_records.ipynb\",\n",
    "    \"timestamp\": timestamp(),\n",
    "    \"periodo_authority_id\": periodo_authority_id,\n",
    "    \"ner_pipeline\": nlp.pipe_names,\n",
    "    \"input_record_count\": record_count        \n",
    "}\n",
    "\n",
    "current_record = 0    \n",
    "for record in input_records or []:        \n",
    "    current_record += 1\n",
    "\n",
    "    # get ID and text from the record\n",
    "    identifier = record.get(\"id\", \"\")\n",
    "    input_text = record.get(\"text\", \"\")\n",
    "\n",
    "    # print progress indicator\n",
    "    print(f\"processing record {current_record} of {record_count} [ID: {identifier}]\")\n",
    "\n",
    "    # slugify identifier in case of bad characters for file names\n",
    "    # TODO: ensure 'output' directory exists first, or create it\n",
    "    baseDirectory = os.path.join(sourceFileDirectory, \"output\")\n",
    "    if \"output\" not in os.listdir(sourceFileDirectory):\n",
    "        os.mkdir(baseDirectory)\n",
    "\n",
    "    output_file_path = f\"./data/output/{slugify(identifier)}.html\"    \n",
    "\n",
    "    # normalise white space prior to annotation\n",
    "    # (extra spaces frustrate pattern matching)\n",
    "    cleaned = normalize_whitespace(input_text)\n",
    "\n",
    "    # perform annotation on cleaned text    \n",
    "    doc = nlp(cleaned)\n",
    "\n",
    "    # write results to html file\n",
    "    metadata[\"identifier\"] = identifier\n",
    "    write_html_file(file_name=output_file_path, doc=doc, metadata=metadata) \n",
    "    # temp interrupt after a few records\n",
    "    if current_record == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ul><li><a href='./data/output/aocarcha1-129642.html'>aocarcha1-129642</a></li><li><a href='./data/output/archaeol6-186501.html'>archaeol6-186501</a></li><li><a href='./data/output/archaeol7-27583.html'>archaeol7-27583</a></li><li><a href='./data/output/archaeol7-404823.html'>archaeol7-404823</a></li><li><a href='./data/output/cambridg1-30423.html'>cambridg1-30423</a></li><li><a href='./data/output/cambridg3-76125.html'>cambridg3-76125</a></li><li><a href='./data/output/colchest3-92994.html'>colchest3-92994</a></li><li><a href='./data/output/cotswold2-93883.html'>cotswold2-93883</a></li><li><a href='./data/output/eastsuss3-7591.html'>eastsuss3-7591</a></li><li><a href='./data/output/essexcou1-41978.html'>essexcou1-41978</a></li><li><a href='./data/output/fieldsec1-100417.html'>fieldsec1-100417</a></li><li><a href='./data/output/molas1-8593.html'>molas1-8593</a></li><li><a href='./data/output/preconst1-3588.html'>preconst1-3588</a></li><li><a href='./data/output/preconst1-3588.html'>preconst1-3588</a></li><li><a href='./data/output/preconst1-4915.html'>preconst1-4915</a></li><li><a href='./data/output/surreyco1-105591.html'>surreyco1-105591</a></li><li><a href='./data/output/thamesva1-93666.html'>thamesva1-93666</a></li><li><a href='./data/output/trentpea1-324597.html'>trentpea1-324597</a></li><li><a href='./data/output/tyneandw3-6189.html'>tyneandw3-6189</a></li><li><a href='./data/output/universi1-91218.html'>universi1-91218</a></li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "input_records_subset = input_records[0:20]\n",
    "# build list of results\n",
    "def result_link(record):\n",
    "    identifier = record[\"id\"] \n",
    "    file_path = f\"./data/output/{slugify(identifier)}.html\"\n",
    "    return f\"<li><a href='{file_path}'>{identifier}</a></li>\" \n",
    "results = list(map(result_link, input_records_subset or []))\n",
    "results.sort()\n",
    "display(HTML(\"<ul>\" + \"\".join(results) + \"</ul>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process OASIS records\n",
    "Vocabulary-based Named Entity Recognition (NER) applied to a set of XML OASIS abstracts obtained from ADS. Detecting temporal phrases and object/monument types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (24.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spacy in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (2.7.2)\n",
      "Requirement already satisfied: jinja2 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (8.1.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipywidgets) (8.24.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: decorator in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "import warnings\n",
    "# suppress user warnings during execution\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "# load required dependencies\n",
    "%pip install --upgrade pip\n",
    "%pip install spacy\n",
    "%pip install ipywidgets\n",
    "%sx python -m spacy download en_core_web_sm\n",
    "\n",
    "#from IPython.display import display, HTML\n",
    "from slugify import slugify # for valid filenames from identifiers\n",
    "import spacy # for NER processing\n",
    "from spacy.tokens import Doc # for NER results\n",
    "from lxml import etree as ET # for parsing input records from XML file\n",
    "from datetime import datetime as DT # for timestamps\n",
    "from html import escape # for writing escaped HTML\n",
    "import pandas as pd  # for DataFrame\n",
    "import os\n",
    "from rematch2 import PeriodoRuler, VocabularyRuler, NegationRuler, DocSummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# write ISO timestamp in consistent format\n",
    "def timestamp():\n",
    "  return DT.now().strftime('%Y-%m-%dT%H:%M:%SZ')  \n",
    "\n",
    "# normalize string whitespace\n",
    "def normalize_whitespace(s: str = \"\") -> str: \n",
    "    return ' '.join(s.strip().split()) \n",
    "    \n",
    "# parse and extract a list of OASIS abstract records from source XML file \n",
    "# returns [{\"id\", \"text\"}, {\"id\", \"text\"}, ...] for subsequent processing\n",
    "def get_records_from_xml_file(file_path: str=\"\") -> list:\n",
    "    records = []\n",
    "    try:\n",
    "        # read XML file\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "    except:\n",
    "        print(f\"Could not read from {file_path}\")\n",
    "        return []\n",
    "\n",
    "    # find rows to be processed in the XML file\n",
    "    rows = tree.xpath(\"/table/rows/row\")\n",
    "\n",
    "    for row in rows:\n",
    "        # find abstract(s) in the current item\n",
    "        abstracts = row.xpath(\"value[@columnNumber='1']/text()\")\n",
    "       \n",
    "        # if multiple abstracts, get first one\n",
    "        if (len(abstracts) > 0):\n",
    "            abstract = abstracts[0]\n",
    "        else:\n",
    "            abstract = \"\"\n",
    "\n",
    "         # find identifier(s) in the current item\n",
    "        identifiers = row.xpath(\"value[@columnNumber='0']/text()\")\n",
    "\n",
    "        # if multiple identifiers, get first one (remove URL prefix if present)\n",
    "        if (len(identifiers) > 0):\n",
    "            identifier = identifiers[0]\n",
    "            identifier = identifier.replace(\n",
    "                \"https://archaeologydataservice.ac.uk/archsearch/record?titleId=\", \"\")\n",
    "        else:\n",
    "            identifier = \"\"\n",
    "\n",
    "        ## create new (cleaned) record and add it\n",
    "        record = {}\n",
    "        record[\"id\"] = str(identifier).strip()\n",
    "        record[\"text\"] = str(abstract).strip()\n",
    "        records.append(record)\n",
    "\n",
    "    # finally, return the extracted list\n",
    "    return records\n",
    "\n",
    "\n",
    "# parse and extract a list of OASIS abstract records from source CSV file \n",
    "# returns [{\"id\", \"text\"}, {\"id\", \"text\"}, ...] for subsequent processing\n",
    "def get_records_from_csv_file(file_path: str=\"\") -> list:\n",
    "    records = []\n",
    "    \n",
    "    # read the CSV file to a DataFrame\n",
    "    df = pd.read_csv(file_path, skip_blank_lines=True)\n",
    "    # set any NaN values to blank string\n",
    "    df.fillna(\"\", inplace=True)\n",
    "    # convert the data to a dict structure\n",
    "    items = df.to_dict(orient=\"records\") \n",
    "    \n",
    "    records = list(map(lambda item: { \n",
    "        \"id\": str(item[\"file\"]).strip(), \n",
    "        \"text\": str(item[\"abstract\"]).strip() }, items))\n",
    "    \n",
    "    return records\n",
    "\n",
    "def result_to_text(doc: Doc = None) -> str:\n",
    "    summary = DocSummary(doc)\n",
    "    \n",
    "\n",
    "# write single results as a HTML file for presentation of output\n",
    "def write_result_to_html_file(file_name: str=\"\", doc: Doc = None, metadata: dict = {}):\n",
    "    summary = DocSummary(doc)\n",
    "    html = []\n",
    "\n",
    "    # write header tags\n",
    "    html.append(\"<!DOCTYPE html>\")\n",
    "    html.append(\"<html>\")\n",
    "        \n",
    "    # write CSS from file to style tag (so no file dependency)\n",
    "    html.append(\"<head>\")\n",
    "    with open('find_pairs.css', 'r', encoding='utf8') as css_file:\n",
    "        css_text = css_file.read()\n",
    "        html.append(f'<style>{css_text}</style>')    \n",
    "    \n",
    "    html.append(\"</head>\")\n",
    "    html.append(\"<body>\")\n",
    "\n",
    "    def metadata_value(key: str) -> str: return str(metadata.get(key.strip(), \"\")).strip()\n",
    "\n",
    "    # write identifier as heading\n",
    "    html.append(\"<h3>\")\n",
    "    identifier = metadata_value(\"identifier\")   \n",
    "    if(identifier.startswith(\"http\")):\n",
    "        html.append(f\"<a target='_blank' rel='noopener noreferrer' href='{identifier}'>{escape(identifier)}</a>\")\n",
    "    else:\n",
    "        html.append(f\"{escape(identifier)}\")\n",
    "    html.append(\"</h3>\")\n",
    "\n",
    "    # write metadata   \n",
    "    html.append(\"<details>\")\n",
    "    html.append(f\"<summary>Metadata</summary>\")\n",
    "    html.append(\"<ul>\")\n",
    "    html.append(f\"<li><strong>identifier:</strong> {escape(metadata_value(\"identifier\"))}</li>\")\n",
    "    html.append(f\"<li><strong>title:</strong> {escape(metadata_value(\"title\"))}</li>\")\n",
    "    html.append(f\"<li><strong>description:</strong> {escape(metadata_value(\"description\"))}</li>\")\n",
    "    html.append(f\"<li><strong>creator:</strong> {escape(metadata_value(\"creator\"))}</li>\")\n",
    "    html.append(f\"<li><strong>created:</strong> {escape(metadata_value(\"timestamp\"))}</li>\")\n",
    "    html.append(f\"<li><strong>periodo authority ID:</strong> {escape(metadata_value(\"periodo_authority_id\"))}</li>\")\n",
    "    html.append(f\"<li><strong>input record source:</strong> {escape(metadata_value(\"input_file_name\"))}</li>\")\n",
    "    html.append(f\"<li><strong>input record count:</strong> {escape(metadata_value(\"input_record_count\"))}</li>\")\n",
    "\n",
    "    pipeline = metadata.get('ner_pipeline', [])\n",
    "    def listitem(value: str) -> str: return f\"<li>{escape(value)}</li>\"\n",
    "    pipelist = \"<ul>\" + \"\".join(list(map(listitem, pipeline))) + \"</ul>\"\n",
    "    html.append(f\"<li><strong>NER pipeline:</strong>{pipelist}</li>\")\n",
    "    html.append(\"</ul>\")\n",
    "    html.append(\"</details>\")    \n",
    "\n",
    "    # write displacy HTML rendering of doc text as paragraph with highlighted spans \n",
    "    html.append(\"<details open>\")\n",
    "    html.append(f\"<summary>Text ({len(summary.doctext('text'))} characters)</summary>\")\n",
    "    doctext = summary.doctext(format=\"html\")\n",
    "    html.append(f\"<p>{doctext}</p>\")\n",
    "    html.append(\"</details>\")\n",
    "\n",
    "    # write list of tokens\n",
    "    html.append(\"<details>\")\n",
    "    html.append(f\"<summary>Tokens ({len(summary.tokens('list'))})</summary>\")        \n",
    "    html.append(summary.tokens(\"htmll\"))\n",
    "    html.append(\"</details>\")\n",
    "\n",
    "    # write label counts\n",
    "    #html.append(\"<details>\")\n",
    "    #html.append(f\"<summary>Label Counts ({len(DocSummary(doc).labelcounts('list'))})</summary>\")\n",
    "    #html.append(DocSummary(doc).labelcounts(format=\"htmlt\"))\n",
    "    #html.append(\"</details>\")\n",
    "    \n",
    "    # write span counts\n",
    "    html.append(\"<details>\")\n",
    "    html.append(f\"<summary>Span Counts ({len(DocSummary(doc).spancounts('list'))})</summary>\")\n",
    "    html.append(DocSummary(doc).spancounts(format=\"htmlt\"))\n",
    "    html.append(\"</details>\")\n",
    "    \n",
    "    # get and write span pairs\n",
    "    html.append(\"<details>\")\n",
    "    html.append(f\"<summary>Span Pairs</summary>\")\n",
    "    pairs = summary.spanpairs(\n",
    "        format=\"htmlt\", \n",
    "        rel_ops=[ \"<\", \">\", \"<<\", \">>\", \".\", \";\" ], \n",
    "        left_labels=[\"PERIOD\", \"YEARSPAN\"], \n",
    "        right_labels=[\"FISH_OBJECT\", \"FISH_MONUMENT\"]\n",
    "        )\n",
    "    html.append(pairs)\n",
    "    html.append(\"</details>\")\n",
    "\n",
    "    html.append(\"<details>\")\n",
    "    html.append(f\"<summary>Negated Pairs</summary>\")\n",
    "    pairs = summary.spanpairs(\n",
    "        format=\"htmlt\", \n",
    "        rel_ops=[ \"<\", \">\", \"<<\", \">>\", \".\", \";\" ], \n",
    "        left_labels=[\"NEGATION\"], \n",
    "        right_labels=[\"YEARSPAN\", \"PERIOD\", \"FISH_OBJECT\", \"FISH_MONUMENT\"]\n",
    "        )\n",
    "    html.append(pairs)\n",
    "    html.append(\"</details>\")\n",
    "    # write footer tags\n",
    "    html.append(\"</body>\")\n",
    "    html.append(\"</html>\")\n",
    "        \n",
    "    # finally, write HTML as string to file\n",
    "    with open(file_name, \"w\") as html_file:\n",
    "        html_file.write(\"\".join(html))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing record 1 of 20 [ID: acarchae2-517986_214251.pdf]\n",
      "processing record 2 of 20 [ID: allenarc1-513712_214540.pdf]\n",
      "processing record 3 of 20 [ID: archaeol3-522422_218251.pdf]\n",
      "processing record 4 of 20 [ID: archaeol5-511552_193431.pdf]\n",
      "processing record 5 of 20 [ID: archaeol6-514817_212394.pdf]\n",
      "processing record 6 of 20 [ID: archaeol6-521703_217323.pdf]\n",
      "processing record 7 of 20 [ID: cotswold2-512313_207882.pdf]\n",
      "processing record 8 of 20 [ID: hs2molah1-502394_219346.pdf]\n",
      "processing record 9 of 20 [ID: molanort1-507471_191809.pdf]\n",
      "processing record 10 of 20 [ID: oxfordar1-513009_208591.pdf]\n",
      "processing record 11 of 20 [ID: oxfordar3-503233_193247.pdf]\n",
      "processing record 12 of 20 [ID: preconst1-516953_216372.pdf]\n",
      "processing record 13 of 20 [ID: thamesva1-510869_192834.pdf]\n",
      "processing record 14 of 20 [ID: wardella2-508249_209161.pdf]\n",
      "processing record 15 of 20 [ID: wessexar1-269267_213359.pdf]\n",
      "processing record 16 of 20 [ID: wessexar1-512723_209282.pdf]\n",
      "processing record 17 of 20 [ID: wessexar1-513366_213387.pdf]\n",
      "processing record 18 of 20 [ID: wessexar1-515034_210676.pdf]\n",
      "processing record 19 of 20 [ID: yorkarch3-511404_193295.pdf]\n",
      "processing record 20 of 20 [ID: yorkarch3-517323_221360.pdf]\n"
     ]
    }
   ],
   "source": [
    "periodo_authority_id = \"p0kh9ds\" # HE Periods list\n",
    "# use predefined spaCy pipeline (English)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable = ['ner'])\n",
    "# add rematch2 NER component(s) to the end of the pipeline\n",
    "nlp.add_pipe(\"yearspan_ruler\", last=True)    \n",
    "nlp.add_pipe(\"periodo_ruler\", last=True, config={\"periodo_authority_id\": periodo_authority_id}) \n",
    "nlp.add_pipe(\"fish_archobjects_ruler\", last=True)\n",
    "nlp.add_pipe(\"fish_monument_types_ruler\", last=True)  \n",
    "nlp.add_pipe(\"fish_supplementary_ruler\", last=True) \n",
    "nlp.add_pipe(\"negation_ruler\", last=True) \n",
    "\n",
    "INPUT_FILEPATH = \"./data/input/report_metadata.csv\"\n",
    "#INPUT_FILEPATH = \"./data/input/journal_metadata.csv\"\n",
    "input_records = get_records_from_csv_file(INPUT_FILEPATH)\n",
    "\n",
    "#INPUT_FILEPATH = \"./data/input/oasis_descr_examples.xml\"\n",
    "#input_records = get_records_from_xml_file(\"./data/input/oasis_descr_examples.xml\")\n",
    "record_count = len(input_records)\n",
    "\n",
    "metadata = {\n",
    "    \"title\": \"process_oasis_records results\",\n",
    "    \"description\": \"vocabulary-based NER annotation of archaeology abstracts\",\n",
    "    \"creator\": \"T4-1-2-NER_OASIS_metadata-records.ipynb\",\n",
    "    \"timestamp\": timestamp(),\n",
    "    \"periodo_authority_id\": periodo_authority_id,\n",
    "    \"ner_pipeline\": nlp.pipe_names,\n",
    "    \"input_file_name\": INPUT_FILEPATH,\n",
    "    \"input_record_count\": record_count        \n",
    "}\n",
    "\n",
    "current_record = 0    \n",
    "for record in input_records or []:        \n",
    "    current_record += 1\n",
    "\n",
    "    # get ID and text from the record\n",
    "    identifier = record.get(\"id\", \"\")\n",
    "    input_text = record.get(\"text\", \"\")\n",
    "\n",
    "    # print progress indicator\n",
    "    print(f\"processing record {current_record} of {record_count} [ID: {identifier}]\")\n",
    "\n",
    "    # slugify identifier in case of bad characters for file names\n",
    "    # TODO: ensure 'output' directory exists first, or create it\n",
    "    output_file_path = f\"./data/output/{slugify(identifier)}.html\"    \n",
    "\n",
    "    # normalise white space prior to annotation\n",
    "    # (extra spaces frustrate pattern matching)\n",
    "    cleaned = normalize_whitespace(input_text)\n",
    "\n",
    "    # perform annotation on cleaned text    \n",
    "    doc = nlp(cleaned)\n",
    "\n",
    "    # write results to html file\n",
    "    metadata[\"identifier\"] = identifier\n",
    "    write_result_to_html_file(file_name=output_file_path, doc=doc, metadata=metadata) \n",
    "    # temp interrupt after a few records\n",
    "    #if current_record == 20:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# build list of results\n",
    "def result_link(record):\n",
    "    identifier = record[\"id\"] \n",
    "    file_path=f\"https://html-preview.github.io/?url=https://github.com/cbinding/rematch2/blob/main/data/output/{slugify(identifier)}.html\"\n",
    "    return f\"<li><a href='{file_path}'>{identifier}</a></li>\" \n",
    "results = list(map(result_link, input_records or []))\n",
    "results.sort()\n",
    "#display(HTML(\"<ul>\" + \"\".join(results) + \"</ul>\"))\n",
    "with open(\"./data/output/results.md\", \"w\") as file:\n",
    "    file.write(\"<ul>\" + \"\".join(results) + \"</ul>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
